{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Notebook 2: Generate Training Data\n",
                "\n",
                "## Goals\n",
                "1. Read all cleaned CSVs from `../balance_sheet_clean_label` and `../income_statement_clean_label`\n",
                "2. Generate context windows for each row (2 previous items, 2 next items)\n",
                "3. Format input strings: `[PREV_2] [PREV_1] [SECTION] [RAW_NAME] [NEXT_1] [NEXT_2]`\n",
                "4. Format target strings: `standardized_name, is_calculated`\n",
                "5. Save as `training_data.jsonl`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Directories set up.\n"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "from pathlib import Path\n",
                "import json\n",
                "\n",
                "# Paths\n",
                "base_path = Path('..')\n",
                "bs_clean_path = base_path / 'balance_sheet_clean_label'\n",
                "is_clean_path = base_path / 'income_statement_clean_label'\n",
                "output_path = base_path / 'data' / 'training_data.jsonl'\n",
                "\n",
                "# Create output directory if needed\n",
                "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "print(\"Directories set up.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Found 92 files to process.\n",
                        "Loaded 92 dataframes.\n"
                    ]
                }
            ],
            "source": [
                "# Load all clean CSVs\n",
                "all_files = list(bs_clean_path.glob('*.csv')) + list(is_clean_path.glob('*.csv'))\n",
                "print(f\"Found {len(all_files)} files to process.\")\n",
                "\n",
                "dataframes = []\n",
                "for f in all_files:\n",
                "    df = pd.read_csv(f)\n",
                "    df['source_file'] = f.name\n",
                "    dataframes.append(df)    \n",
                "\n",
                "print(f\"Loaded {len(dataframes)} dataframes.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_context_string(row_idx, df):\n",
                "    \"\"\"\n",
                "    Creates the input string for a given row index.\n",
                "    Format: [PREV_2] [PREV_1] [SECTION] [RAW_NAME] [NEXT_1] [NEXT_2]\n",
                "    \"\"\"\n",
                "    # Current item\n",
                "    row = df.iloc[row_idx]\n",
                "    section = row['section']\n",
                "    raw_name = str(row['row_name']).strip()\n",
                "    \n",
                "    # Previous items\n",
                "    if row_idx >= 1:\n",
                "        prev1 = str(df.iloc[row_idx-1]['row_name']).strip()\n",
                "    else:\n",
                "        prev1 = \"<START>\"\n",
                "        \n",
                "    if row_idx >= 2:\n",
                "        prev2 = str(df.iloc[row_idx-2]['row_name']).strip()\n",
                "    else:\n",
                "        prev2 = \"<START>\"\n",
                "        \n",
                "    # Next items\n",
                "    if row_idx + 1 < len(df):\n",
                "        next1 = str(df.iloc[row_idx+1]['row_name']).strip()\n",
                "    else:\n",
                "        next1 = \"<END>\"\n",
                "        \n",
                "    if row_idx + 2 < len(df):\n",
                "        next2 = str(df.iloc[row_idx+2]['row_name']).strip()\n",
                "    else:\n",
                "        next2 = \"<END>\"\n",
                "\n",
                "    # Construct string\n",
                "    input_str = f\"[{prev2}] [{prev1}] [{section}] [{raw_name}] [{next1}] [{next2}]\"\n",
                "    return input_str"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Generated 2079 training examples.\n",
                        "Sample Input:  [<START>] [<START>] [current_assets] [Cash and cash equivalents] [Marketable securities (current)] [Accounts receivable, net]\n",
                        "Sample Output: cash_and_equivalents\n"
                    ]
                }
            ],
            "source": [
                "# Generate Training Data\n",
                "training_rows = []\n",
                "for df in dataframes:\n",
                "    # Ensure we sort if needed, but CSVs are likely in order\n",
                "    # df = df.sort_index() \n",
                "    \n",
                "    for i in range(len(df)):\n",
                "        input_text = create_context_string(i, df)\n",
                "        \n",
                "        # Target: Just standardized_name\n",
                "        target_text = str(df.iloc[i]['standardized_name']).strip()\n",
                "        \n",
                "        training_rows.append({\n",
                "            \"input\": input_text,\n",
                "            \"output\": target_text,\n",
                "            \"metadata\": {\n",
                "                \"source\": df.iloc[i]['source_file'],\n",
                "                # We keep is_calculated in metadata so we can build a lookup table later\n",
                "                \"is_calculated\": bool(df.iloc[i]['is_calculated'])\n",
                "            }\n",
                "        })\n",
                "        \n",
                "print(f\"Generated {len(training_rows)} training examples.\")\n",
                "print(\"Sample Input: \", training_rows[0]['input'])\n",
                "print(\"Sample Output:\", training_rows[0]['output'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Rows before filtering headers: 2079\n",
                        "Rows after filtering headers: 2009\n"
                    ]
                }
            ],
            "source": [
                "# OPTIONAL: Remove Header Rows\n",
                "# Uncomment the lines below to exclude any row ending in '_header'\n",
                "# from the training set.\n",
                "\n",
                "print(f\"Rows before filtering headers: {len(training_rows)}\")\n",
                "training_rows = [\n",
                "    row for row in training_rows \n",
                "    if not row['output'].endswith('_header')\n",
                "]\n",
                "print(f\"Rows after filtering headers: {len(training_rows)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "✓ Saved to ..\\data\\training_data.jsonl\n"
                    ]
                }
            ],
            "source": [
                "# Save to JSONL\n",
                "with open(output_path, 'w', encoding='utf-8') as f:\n",
                "    for row in training_rows:\n",
                "        f.write(json.dumps(row) + '\\n')\n",
                "        \n",
                "print(f\"✓ Saved to {output_path}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "myaiml",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
