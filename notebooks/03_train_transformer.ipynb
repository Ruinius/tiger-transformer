{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Notebook 3: Train Transformer\n",
                "\n",
                "## Goals\n",
                "1. Load `training_data.jsonl`\n",
                "2. Prepare Label Mappings (Unique Output -> ID)\n",
                "3. Split Data by **Company** (Train/Val)\n",
                "4. Tokenize Inputs using `FinBert`\n",
                "5. Fine-tune Model (Sequence Classification head)\n",
                "6. Evaluate & Save Best Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Using device: cuda\n"
                    ]
                }
            ],
            "source": [
                "import json\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from pathlib import Path\n",
                "import shutil\n",
                "import torch\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from transformers import BertTokenizerFast, BertForSequenceClassification, Trainer, TrainingArguments\n",
                "from sklearn.metrics import accuracy_score\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Check device\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"Using device: {device}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loaded 2497 examples.\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>input</th>\n",
                            "      <th>output</th>\n",
                            "      <th>metadata</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>[&lt;START&gt;] [&lt;START&gt;] [current_assets] [Cash and...</td>\n",
                            "      <td>cash_and_equivalents</td>\n",
                            "      <td>{'source': 'AAPL.csv', 'is_calculated': False}</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>[&lt;START&gt;] [Cash and cash equivalents] [current...</td>\n",
                            "      <td>short_term_investments</td>\n",
                            "      <td>{'source': 'AAPL.csv', 'is_calculated': False}</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>[Cash and cash equivalents] [Marketable securi...</td>\n",
                            "      <td>accounts_receivable</td>\n",
                            "      <td>{'source': 'AAPL.csv', 'is_calculated': False}</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>[Marketable securities (current)] [Accounts re...</td>\n",
                            "      <td>other_current_assets</td>\n",
                            "      <td>{'source': 'AAPL.csv', 'is_calculated': False}</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>[Accounts receivable, net] [Vendor non-trade r...</td>\n",
                            "      <td>inventory</td>\n",
                            "      <td>{'source': 'AAPL.csv', 'is_calculated': False}</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                               input                  output  \\\n",
                            "0  [<START>] [<START>] [current_assets] [Cash and...    cash_and_equivalents   \n",
                            "1  [<START>] [Cash and cash equivalents] [current...  short_term_investments   \n",
                            "2  [Cash and cash equivalents] [Marketable securi...     accounts_receivable   \n",
                            "3  [Marketable securities (current)] [Accounts re...    other_current_assets   \n",
                            "4  [Accounts receivable, net] [Vendor non-trade r...               inventory   \n",
                            "\n",
                            "                                         metadata  \n",
                            "0  {'source': 'AAPL.csv', 'is_calculated': False}  \n",
                            "1  {'source': 'AAPL.csv', 'is_calculated': False}  \n",
                            "2  {'source': 'AAPL.csv', 'is_calculated': False}  \n",
                            "3  {'source': 'AAPL.csv', 'is_calculated': False}  \n",
                            "4  {'source': 'AAPL.csv', 'is_calculated': False}  "
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Load Data\n",
                "data_path = Path('../data/training_data.jsonl')\n",
                "\n",
                "with open(data_path, 'r', encoding='utf-8') as f:\n",
                "    raw_data = [json.loads(line) for line in f]\n",
                "    \n",
                "df = pd.DataFrame(raw_data)\n",
                "print(f\"Loaded {len(df)} examples.\")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Total unique labels: 158\n",
                        "Sample labels: ['cash_and_equivalents', 'short_term_investments', 'accounts_receivable', 'other_current_assets', 'inventory']\n"
                    ]
                }
            ],
            "source": [
                "# Create Label Mappings\n",
                "# Our target is 'output' column\n",
                "labels = df['output'].unique().tolist()\n",
                "label2id = {label: i for i, label in enumerate(labels)}\n",
                "id2label = {i: label for label, i in label2id.items()}\n",
                "\n",
                "num_labels = len(labels)\n",
                "print(f\"Total unique labels: {num_labels}\")\n",
                "\n",
                "# Save mappings for inference later\n",
                "with open('../models/label_map.json', 'w') as f:\n",
                "    json.dump(label2id, f, indent=2)\n",
                "    \n",
                "print(\"Sample labels:\", labels[:5])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Using ALL data for training.\n",
                        "Train size: 2497 rows\n",
                        "Val size: 2497 rows (Same as train)\n"
                    ]
                }
            ],
            "source": [
                "# TRAINING ON ALL DATA (No separate validation split)\n",
                "print(\"Using ALL data for training.\")\n",
                "train_df = df.copy()\n",
                "val_df = df.copy()  # Use train data for val just effectively disables unknown-validation\n",
                "print(f\"Train size: {len(train_df)} rows\")\n",
                "print(f\"Val size: {len(val_df)} rows (Same as train)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Custom Dataset\n",
                "class FinancialDataset(Dataset):\n",
                "    def __init__(self, encodings, labels):\n",
                "        self.encodings = encodings\n",
                "        self.labels = labels\n",
                "\n",
                "    def __getitem__(self, idx):\n",
                "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
                "        item['labels'] = torch.tensor(self.labels[idx])\n",
                "        return item\n",
                "\n",
                "    def __len__(self):\n",
                "        return len(self.labels)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CHANGED: Use FinBERT pre-trained model\n",
                "model_name = 'yiyanghkust/finbert-pretrain' \n",
                "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
                "\n",
                "train_encodings = tokenizer(train_df['input'].tolist(), truncation=True, padding=True, max_length=128)\n",
                "val_encodings = tokenizer(val_df['input'].tolist(), truncation=True, padding=True, max_length=128)\n",
                "\n",
                "# Convert labels to IDs\n",
                "train_labels = [label2id[l] for l in train_df['output']]\n",
                "val_labels = [label2id[l] for l in val_df['output']]\n",
                "\n",
                "train_dataset = FinancialDataset(train_encodings, train_labels)\n",
                "val_dataset = FinancialDataset(val_encodings, val_labels)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at yiyanghkust/finbert-pretrain and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
                        "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
                    ]
                }
            ],
            "source": [
                "# CHANGED: Use BertForSequenceClassification\n",
                "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
                "\n",
                "model.to(device)\n",
                "\n",
                "# Metrics function\n",
                "def compute_metrics(pred):\n",
                "    labels = pred.label_ids\n",
                "    preds = pred.predictions.argmax(-1)\n",
                "    acc = accuracy_score(labels, preds)\n",
                "    return {'accuracy': acc}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CHANGED for FinBERT\n",
                "training_args = TrainingArguments(\n",
                "    output_dir='../models/results',\n",
                "    num_train_epochs=15,\n",
                "    per_device_train_batch_size=8,    # Lower batch size to fit in 8GB VRAM\n",
                "    per_device_eval_batch_size=16,    # Lower eval batch size just in case\n",
                "    gradient_accumulation_steps=2,    # Simulate batch size of 16 (8 * 2)\n",
                "    fp16=True,                        # Use mixed precision (crucial for 2060 Super)\n",
                "    warmup_steps=100,\n",
                "    weight_decay=0.01,\n",
                "    logging_dir='../models/logs',\n",
                "    logging_steps=10,\n",
                "    eval_strategy=\"epoch\",\n",
                "    save_strategy=\"epoch\",\n",
                "    load_best_model_at_end=True,\n",
                "    metric_for_best_model=\"accuracy\"\n",
                ")\n",
                "\n",
                "\n",
                "\n",
                "trainer = Trainer(\n",
                "    model=model,\n",
                "    args=training_args,\n",
                "    train_dataset=train_dataset,\n",
                "    eval_dataset=val_dataset,\n",
                "    compute_metrics=compute_metrics\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "\n",
                            "    <div>\n",
                            "      \n",
                            "      <progress value='2340' max='2340' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
                            "      [2340/2340 06:40, Epoch 14/15]\n",
                            "    </div>\n",
                            "    <table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            " <tr style=\"text-align: left;\">\n",
                            "      <th>Epoch</th>\n",
                            "      <th>Training Loss</th>\n",
                            "      <th>Validation Loss</th>\n",
                            "      <th>Accuracy</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <td>1</td>\n",
                            "      <td>2.702900</td>\n",
                            "      <td>2.476852</td>\n",
                            "      <td>0.532239</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>2</td>\n",
                            "      <td>1.172400</td>\n",
                            "      <td>0.877504</td>\n",
                            "      <td>0.863837</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>3</td>\n",
                            "      <td>0.551200</td>\n",
                            "      <td>0.440376</td>\n",
                            "      <td>0.925110</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>4</td>\n",
                            "      <td>0.493400</td>\n",
                            "      <td>0.275071</td>\n",
                            "      <td>0.956748</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>5</td>\n",
                            "      <td>0.189600</td>\n",
                            "      <td>0.182891</td>\n",
                            "      <td>0.972767</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>6</td>\n",
                            "      <td>0.217500</td>\n",
                            "      <td>0.136586</td>\n",
                            "      <td>0.981978</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>7</td>\n",
                            "      <td>0.084100</td>\n",
                            "      <td>0.088909</td>\n",
                            "      <td>0.991590</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>8</td>\n",
                            "      <td>0.103900</td>\n",
                            "      <td>0.063299</td>\n",
                            "      <td>0.995595</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>9</td>\n",
                            "      <td>0.066700</td>\n",
                            "      <td>0.047771</td>\n",
                            "      <td>0.997998</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>10</td>\n",
                            "      <td>0.077100</td>\n",
                            "      <td>0.035702</td>\n",
                            "      <td>0.997597</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>11</td>\n",
                            "      <td>0.042000</td>\n",
                            "      <td>0.028555</td>\n",
                            "      <td>0.998799</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>12</td>\n",
                            "      <td>0.066600</td>\n",
                            "      <td>0.024160</td>\n",
                            "      <td>0.998799</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>13</td>\n",
                            "      <td>0.038300</td>\n",
                            "      <td>0.020887</td>\n",
                            "      <td>0.999199</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>14</td>\n",
                            "      <td>0.017600</td>\n",
                            "      <td>0.018775</td>\n",
                            "      <td>0.999199</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table><p>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/plain": [
                            "TrainOutput(global_step=2340, training_loss=0.5320685464602251, metrics={'train_runtime': 401.8941, 'train_samples_per_second': 93.196, 'train_steps_per_second': 5.822, 'total_flos': 1417756885991280.0, 'train_loss': 0.5320685464602251, 'epoch': 14.907348242811501})"
                        ]
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Train!\n",
                "trainer.train()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Model saved to ..\\models\\financial_transformer\n"
                    ]
                }
            ],
            "source": [
                "# Save Final Model\n",
                "save_path = Path('../models/financial_transformer')\n",
                "model.save_pretrained(save_path)\n",
                "tokenizer.save_pretrained(save_path)\n",
                "\n",
                "print(f\"Model saved to {save_path}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Quantizing model...\n",
                        "✓ Quantized model saved to: ..\\models\\financial_transformer_quantized.pt\n",
                        "Original Size:  419.16 MB\n",
                        "Quantized Size: 174.24 MB\n",
                        "Compression:    2.4x smaller\n"
                    ]
                }
            ],
            "source": [
                "# ==========================================\n",
                "# OPTIONAL: POST-TRAINING QUANTIZATION\n",
                "# ==========================================\n",
                "\n",
                "import torch.quantization\n",
                "print(\"Quantizing model...\")\n",
                "# 1. Load the best saved model (we use the path where we saved FinBERT earlier)\n",
                "# CHANGED: Use BertForSequenceClassification instead of DistilBert\n",
                "model_to_quantize = BertForSequenceClassification.from_pretrained('../models/financial_transformer')\n",
                "model_to_quantize.to('cpu')  # Quantization is typically done on CPU in PyTorch\n",
                "# 2. Apply Dynamic Quantization\n",
                "# This targets the Linear layers (weights) to convert to int8\n",
                "quantized_model = torch.quantization.quantize_dynamic(\n",
                "    model_to_quantize,\n",
                "    {torch.nn.Linear},  # Layers to quantize\n",
                "    dtype=torch.qint8\n",
                ")\n",
                "# 3. Save Quantized Model\n",
                "quant_save_path = Path('../models/financial_transformer_quantized.pt')\n",
                "torch.save(quantized_model.state_dict(), quant_save_path)\n",
                "# Compare sizes\n",
                "# Note: Newer transformers save 'model.safetensors' by default\n",
                "model_file = Path('../models/financial_transformer/model.safetensors')\n",
                "if not model_file.exists():\n",
                "    model_file = Path('../models/financial_transformer/pytorch_model.bin')\n",
                "original_size = model_file.stat().st_size / (1024 * 1024)\n",
                "quantized_size = quant_save_path.stat().st_size / (1024 * 1024)\n",
                "print(f\"✓ Quantized model saved to: {quant_save_path}\")\n",
                "print(f\"Original Size:  {original_size:.2f} MB\")\n",
                "print(f\"Quantized Size: {quantized_size:.2f} MB\")\n",
                "print(f\"Compression:    {original_size / quantized_size:.1f}x smaller\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "✓ Deleted interim checkpoints at: ..\\models\\results\n"
                    ]
                }
            ],
            "source": [
                "# Clean up massive checkpoint folder\n",
                "checkpoint_dir = Path('../models/results')\n",
                "if checkpoint_dir.exists() and checkpoint_dir.is_dir():\n",
                "    try:\n",
                "        shutil.rmtree(checkpoint_dir)\n",
                "        print(f\"✓ Deleted interim checkpoints at: {checkpoint_dir}\")\n",
                "    except Exception as e:\n",
                "        print(f\"Error deleting folder: {e}\")\n",
                "else:\n",
                "    print(\"Checkpoint folder already deleted or does not exist.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "myaiml",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
